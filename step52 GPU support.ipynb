{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor Product at `GPU` is much faster then `CPU`\n",
    "\n",
    "Most deep learning calculation is held by `Matrix Multiplication`<br>\n",
    "We will make `Dezero` to use `GPU`\n",
    "\n",
    "---\n",
    "\n",
    "- install `cupy` for `GPU` usage\n",
    "    - Library for parallel calculation using GPU\n",
    "\n",
    "```python\n",
    "$ pip install cupy\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "If the pip doesn't work and your at `Win10` then try the following\n",
    "\n",
    "```python\n",
    "$ conda install -c conda-forge cupy cudatoolkit\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUDA / cuDNN\n",
    "\n",
    "- Check the appropriate CUDA version for your graphic card\n",
    "    - https://en.wikipedia.org/wiki/CUDA#Version_features_and_specifications\n",
    "- Install CUDA\n",
    "    - https://developer.nvidia.com/cuda-toolkit-archive\n",
    "- Install cuDNN\n",
    "    - https://developer.nvidia.com/cudnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Numpy` & `Cupy`\n",
    "\n",
    "Both usage are almost the same :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 2]\n",
      " [3 4 5]]\n",
      "[ 3 12]\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "x = cp.arange(6).reshape(2, 3)\n",
    "print(x)\n",
    "\n",
    "y = x.sum(axis=1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cupy.core.core.ndarray"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can send data back and forth\n",
    "- `cp.asarray` - **Main Memory** -> **GPU Memory**\n",
    "- `cp.asnumpy` - **GPU Memory** -> **Main Memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# numpy -> cupy\n",
    "n = np.array([1, 2, 3])\n",
    "c = cp.asarray(n)\n",
    "\n",
    "assert type(c) == cp.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cupy -> numpy\n",
    "c = cp.array([1, 2, 3])\n",
    "n = cp.asnumpy(c)\n",
    "\n",
    "assert type(n) == np.ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caution\n",
    "\n",
    "This memory movement could be a bottleneck when we treat big data.<br>\n",
    "It's important to code the memory movement less as possible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `cp.get_array_module`\n",
    "\n",
    "Tell is this tensor `numpy` or `cupy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array\n",
    "x = np.array([1, 2, 3])\n",
    "xp = cp.get_array_module(x)\n",
    "assert xp == np\n",
    "\n",
    "# cupy array\n",
    "x = cp.array([1, 2, 3])\n",
    "xp = cp.get_array_module(x)\n",
    "assert xp == cp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can write **compatible code** for both `numpy` and `cupy` with **`cp.get_array_module`** :)\n",
    "\n",
    "```python\n",
    "xp = cp.get_array_module(x)\n",
    "\n",
    "y = xp.sin(x)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuda Module\n",
    "\n",
    "Compatible with the computer which doesn't have `GPU` or `cupy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "gpu_enable  = True\n",
    "\n",
    "try:\n",
    "    import cupy as cp\n",
    "    cupy = cp\n",
    "except ImportError:\n",
    "    gpu_enable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are making a wrapper functions of `cupy` to correspond the situation when `cupy` is not installed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dezero import Variable\n",
    "\n",
    "def get_array_module(x):\n",
    "    if isinstance(x, Variable):\n",
    "        x = x.data\n",
    "        \n",
    "    if not gpu_enable:\n",
    "        return np\n",
    "    \n",
    "    xp  = cp.get_array_module(x)\n",
    "    return xp\n",
    "\n",
    "def as_numpy(x):\n",
    "    if isinstance(x, Variable):\n",
    "        x = x.data\n",
    "    \n",
    "    # This code is necessary when cupy is not installed\n",
    "    if np.isscalar(x):\n",
    "        return np.array(x)\n",
    "    elif isinstance(x, np.ndarray):\n",
    "        return x\n",
    "    \n",
    "    return cp.asnumpy(x)\n",
    "\n",
    "def as_cupy(x):\n",
    "    if isinstance(x, Variable):\n",
    "        x = x.data\n",
    "        \n",
    "    if not gpu_enable:\n",
    "        raise Exception('Cannot load Cupy. Install Cupy.')\n",
    "        \n",
    "    return cp.asarray(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.asnumpy(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(None, dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isscalar(np.array(1)), np.isscalar(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "object __array__ method not producing an array",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-5574df7f7850>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: object __array__ method not producing an array"
     ]
    }
   ],
   "source": [
    "np.array(cp.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.array(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.array(cp.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only using `cp.asnumpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.asnumpy(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.asnumpy(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.asnumpy(cp.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "only using `cp.asarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.asarray(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.asarray(cp.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp.asarray(np.array([1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify `dezero` for `cupy` compatible\n",
    "- Variable\n",
    "- Layer\n",
    "- DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "...\n",
    "\n",
    "try:\n",
    "    import cupy\n",
    "    array_types = (np.ndarray, cupy.ndarray)\n",
    "except ImportError:\n",
    "    array_types = (np.ndarray)\n",
    "\n",
    "    \n",
    "class Variable:\n",
    "\n",
    "    def __init__(self, data, name=None):\n",
    "        if data is not None:\n",
    "            if not isinstance(data, array_types):\n",
    "                raise TypeError(f'{type(data)} is not supported')\n",
    "\n",
    "    def backward(self, retain_grad=False, create_graph=False):\n",
    "        if self.grad is None:\n",
    "            # self.grad = np.ones_like(self.data)\n",
    "            xp = dezero.cuda.get_array_module(self.data)\n",
    "            self.grad = Variable(xp.ones_like(self.data))\n",
    "\n",
    "    ...\n",
    "    \n",
    "    -> add new functions!\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        if self.data is not None:\n",
    "            self.data = dezero.cuda.as_numpy(self.data)\n",
    "            \n",
    "    def to_gpu(self):\n",
    "        if self.data is not None:\n",
    "            self.data = dezero.cuda.as_cupy(self.data)\n",
    "```\n",
    "\n",
    "Now for the `Layer`\n",
    "\n",
    "```python\n",
    "class Layer:\n",
    "    ...\n",
    "    \n",
    "    def to_cpu(self):\n",
    "        for param in self.params():\n",
    "            param.to_cpu()\n",
    "        \n",
    "    def to_gpu(self):\n",
    "        for param in self.params():\n",
    "            param.to_gpu()\n",
    "```\n",
    "\n",
    "And finally for the `DataLoader`\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from dezero import cuda\n",
    "\n",
    "class DataLoader:\n",
    "    def __init__(self, dataset, batch_size, shuffle=True, gpu=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.data_size = len(dataset)\n",
    "        self.max_iter = math.ceil(self.data_size / batch_size)\n",
    "        self.gpu = gpu\n",
    "\n",
    "        self.reset()\n",
    "\n",
    "    def __next__(self):\n",
    "        \n",
    "        ...\n",
    "        \n",
    "        xp = cuda.cupy if self.gpu else np\n",
    "        x = xp.array([example[0] for example in batch])\n",
    "        y = xp.array([example[1] for example in batch])\n",
    "\n",
    "        self.iteration += 1\n",
    "\n",
    "        return x, y\n",
    "\n",
    "    def to_cpu(self):\n",
    "        self.gpu = False\n",
    "        \n",
    "    def to_gpu(self):\n",
    "        self.gpu = True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify `np.xxx` usage\n",
    "\n",
    "change the functions for the compatibility with `cupy` and `numpy`\n",
    "\n",
    "```python\n",
    "import dezero import cuda\n",
    "\n",
    "xp = cuda.get_array_module(x)\n",
    "y = xp.sin(x)\n",
    "```\n",
    "\n",
    "- **`functions.py`**\n",
    "    - Sin\n",
    "    - Cos\n",
    "    - Tanh\n",
    "    - Exp\n",
    "    - Log\n",
    "    \n",
    "    - GetItemGrad\n",
    "        - numpy - `np.add.at`\n",
    "        - cupy - `cp.scatter_add`\n",
    "    - Sigmoid\n",
    "    - ReLU\n",
    "    - Softmax\n",
    "    - SoftmaxCrossEntropy\n",
    "    - logsoftmax\n",
    "    - Clip\n",
    "    \n",
    "- **`layers.py`**\n",
    "    - Linear\n",
    "    \n",
    "- **`optimizers.py`**\n",
    "    - MomentumSGD\n",
    "    - AdaGrad\n",
    "    - RMSProp\n",
    "    - AdaDelta\n",
    "    - Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**cp.scatter_add**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cupy as cp\n",
    "\n",
    "test = cp.array([0, 0, 0])\n",
    "cp.scatter_add(test, 1, 1)\n",
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify `core.py`\n",
    "\n",
    "change the functions for the compatibility with `cupy` and `numpy`\n",
    "\n",
    "```python\n",
    "def as_array(x, array_module=np):\n",
    "    if np.isscalar(x):\n",
    "        return array_module.array(x)\n",
    "    return x\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only scalar value will be treated as True\n",
    "np.isscalar(cp.array(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isscalar(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arithmetic operations\n",
    "\n",
    "```python\n",
    "def add(x0, x1):\n",
    "    x1 = as_array(x1, array_module=dezero.cuda.get_array_module(x0.data))\n",
    "    return Add()(x0, x1)\n",
    "```\n",
    "\n",
    "- add\n",
    "- sub\n",
    "- rsub\n",
    "- mul\n",
    "- div\n",
    "- rdiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MNIST` with `GPU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import dezero\n",
    "from dezero import optimizers\n",
    "from dezero import DataLoader\n",
    "\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "from dezero.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "hidden_size = 1000\n",
    "\n",
    "train_set = MNIST(train=True)\n",
    "test_set = MNIST(train=False)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "test_loader = DataLoader(test_set, batch_size, shuffle=False)\n",
    "\n",
    "model = MLP((hidden_size, 10))\n",
    "optimizer = optimizers.SGD(lr=0.1).setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with `gpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dezero.cuda.gpu_enable:\n",
    "    train_loader.to_gpu()\n",
    "    test_loader.to_gpu()\n",
    "    model.to_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "train loss: 0.9686, accuracy: 0.7228, time: 4.7941[sec]\n",
      "test loss: 0.4324, accuracy: 0.8818\n",
      "epoch : 2\n",
      "train loss: 0.4005, accuracy: 0.8855, time: 4.3793[sec]\n",
      "test loss: 0.3684, accuracy: 0.8939\n",
      "epoch : 3\n",
      "train loss: 0.3511, accuracy: 0.8978, time: 4.3744[sec]\n",
      "test loss: 0.3292, accuracy: 0.9045\n",
      "epoch : 4\n",
      "train loss: 0.3287, accuracy: 0.9054, time: 4.3783[sec]\n",
      "test loss: 0.3230, accuracy: 0.9090\n",
      "epoch : 5\n",
      "train loss: 0.3165, accuracy: 0.9087, time: 4.3444[sec]\n",
      "test loss: 0.2991, accuracy: 0.9139\n"
     ]
    }
   ],
   "source": [
    "epoch_list = []\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    start = time.time()\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = F.softmax_cross_entropy(y_pred, y)\n",
    "        acc = F.accuracy(y_pred, y)\n",
    "        \n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        \n",
    "        sum_loss += float(loss.data) * len(y)\n",
    "        sum_acc += float(acc.data) * len(y)\n",
    "    \n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "\n",
    "    train_loss_list.append(avg_loss)\n",
    "    train_acc_list.append(avg_acc)\n",
    "\n",
    "    elasped_time = time.time() - start\n",
    "    \n",
    "    print('epoch : {}'.format(epoch + 1))\n",
    "    print('train loss: {:.4f}, accuracy: {:.4f}, time: {:.4f}[sec]'.format(avg_loss, avg_acc, elasped_time))\n",
    "    \n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    \n",
    "    with dezero.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            \n",
    "            loss = F.softmax_cross_entropy(y_pred, y)\n",
    "            acc = F.accuracy(y_pred, y)\n",
    "            \n",
    "            sum_loss += float(loss.data) * len(y)\n",
    "            sum_acc += float(acc.data) * len(y)\n",
    "            \n",
    "    avg_loss = sum_loss / len(test_set)\n",
    "    avg_acc = sum_acc / len(test_set)            \n",
    "    \n",
    "    test_loss_list.append(avg_loss)\n",
    "    test_acc_list.append(avg_acc)\n",
    "\n",
    "    print('test loss: {:.4f}, accuracy: {:.4f}'.format(avg_loss, avg_acc))\n",
    "    \n",
    "    epoch_list.append(epoch + 1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader.to_cpu()\n",
    "test_loader.to_cpu()\n",
    "model.to_cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "train loss: 0.3054, accuracy: 0.9118, time: 5.3513[sec]\n",
      "test loss: 0.2879, accuracy: 0.9174\n",
      "epoch : 2\n",
      "train loss: 0.2983, accuracy: 0.9133, time: 5.6289[sec]\n",
      "test loss: 0.2853, accuracy: 0.9178\n",
      "epoch : 3\n",
      "train loss: 0.2923, accuracy: 0.9153, time: 6.0089[sec]\n",
      "test loss: 0.2871, accuracy: 0.9163\n",
      "epoch : 4\n",
      "train loss: 0.2865, accuracy: 0.9175, time: 5.4624[sec]\n",
      "test loss: 0.2760, accuracy: 0.9208\n",
      "epoch : 5\n",
      "train loss: 0.2814, accuracy: 0.9191, time: 5.6888[sec]\n",
      "test loss: 0.2713, accuracy: 0.9224\n"
     ]
    }
   ],
   "source": [
    "epoch_list = []\n",
    "\n",
    "train_loss_list = []\n",
    "test_loss_list = []\n",
    "\n",
    "train_acc_list = []\n",
    "test_acc_list = []\n",
    "\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    start = time.time()\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = F.softmax_cross_entropy(y_pred, y)\n",
    "        acc = F.accuracy(y_pred, y)\n",
    "        \n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        \n",
    "        sum_loss += float(loss.data) * len(y)\n",
    "        sum_acc += float(acc.data) * len(y)\n",
    "    \n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "\n",
    "    train_loss_list.append(avg_loss)\n",
    "    train_acc_list.append(avg_acc)\n",
    "\n",
    "    elasped_time = time.time() - start\n",
    "    \n",
    "    print('epoch : {}'.format(epoch + 1))\n",
    "    print('train loss: {:.4f}, accuracy: {:.4f}, time: {:.4f}[sec]'.format(avg_loss, avg_acc, elasped_time))\n",
    "    \n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    \n",
    "    with dezero.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            y_pred = model(x)\n",
    "            \n",
    "            \n",
    "            loss = F.softmax_cross_entropy(y_pred, y)\n",
    "            acc = F.accuracy(y_pred, y)\n",
    "            \n",
    "            sum_loss += float(loss.data) * len(y)\n",
    "            sum_acc += float(acc.data) * len(y)\n",
    "            \n",
    "    avg_loss = sum_loss / len(test_set)\n",
    "    avg_acc = sum_acc / len(test_set)            \n",
    "    \n",
    "    test_loss_list.append(avg_loss)\n",
    "    test_acc_list.append(avg_acc)\n",
    "\n",
    "    print('test loss: {:.4f}, accuracy: {:.4f}'.format(avg_loss, avg_acc))\n",
    "    \n",
    "    epoch_list.append(epoch + 1)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `gpu` - 4 sec,  `cpu` - 6 sec\n",
    "\n",
    "There is a bit difference but not that big here :0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
