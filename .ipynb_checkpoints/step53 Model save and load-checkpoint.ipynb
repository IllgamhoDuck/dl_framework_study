{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save & Load\n",
    "\n",
    "In case of `cupy` we could transform to `numpy` so we will only consider saving as `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "np.save('test.npy', x)\n",
    "\n",
    "x = np.load('test.npy')\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How about saving several arrays?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([1, 2, 3])\n",
    "x2 = np.array([4, 5, 6])\n",
    "\n",
    "np.savez('test.npz', x1=x1, x2=x2)\n",
    "\n",
    "arrays = np.load('test.npz')\n",
    "\n",
    "x1 = arrays['x1']\n",
    "x2 = arrays['x2']\n",
    "\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`dict` use - Above is the same as below**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 2 3]\n",
      "[4 5 6]\n"
     ]
    }
   ],
   "source": [
    "x1 = np.array([1, 2, 3])\n",
    "x2 = np.array([4, 5, 6])\n",
    "data = {'x1': x1, 'x2': x2}\n",
    "\n",
    "np.savez('test.npz', **data)\n",
    "\n",
    "arrays = np.load('test.npz')\n",
    "\n",
    "x1 = arrays['x1']\n",
    "x2 = arrays['x2']\n",
    "\n",
    "print(x1)\n",
    "print(x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `np.savez_compressed` = `np.savez` + compress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `Flatten` Layer's `parameters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dezero import Parameter\n",
    "from dezero import Layer\n",
    "\n",
    "layer = Layer()\n",
    "\n",
    "l1 = Layer()\n",
    "l1.p1 = Parameter(np.array(1))\n",
    "\n",
    "layer.l1 = l1\n",
    "layer.p2 = Parameter(np.array(2))\n",
    "layer.p3 = Parameter(np.array(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "class Layer:\n",
    "    ...\n",
    "    def _flatten_params(self, params_dict, parent_key=\"\"):\n",
    "        for name in self._params:\n",
    "            obj = self.__dict__[name]\n",
    "            key = parent_key + '/' + name if parent_key else name\n",
    "\n",
    "            if isinstance(obj, Layer):\n",
    "                obj._flatten_params(params_dict, key)\n",
    "            else:\n",
    "                params_dict[key] = obj\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'p3': Variable(3), 'l1/p1': Variable(1), 'p2': Variable(2)}\n"
     ]
    }
   ],
   "source": [
    "params_dict = {}\n",
    "layer._flatten_params(params_dict)\n",
    "print(params_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Layer class `save` & `load`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "import os\n",
    "\n",
    "class Layer:\n",
    "    ...\n",
    "    def save_weights(self, path):\n",
    "        # was model using gpu before save?\n",
    "        using_gpu = False\n",
    "\n",
    "        if self.gpu:\n",
    "            self.to_cpu()\n",
    "            using_gpu = True\n",
    "\n",
    "        params_dict = {}\n",
    "        self._flatten_params(params_dict)\n",
    "        array_dict = {key: param.data for key, param in params_dict.items()}\n",
    "\n",
    "        try:\n",
    "            np.savez_compressed(path, **array_dict)\n",
    "        except (Exception, KeyboardInterrupt) as e:\n",
    "            if os.path.exists(path):\n",
    "                os.remove(path)\n",
    "            raise\n",
    "\n",
    "        # if model was using gpu restore it!\n",
    "        if using_gpu:\n",
    "            self.to_gpu()\n",
    "\n",
    "    def load_weights(self, path):\n",
    "        npz = np.load(path)\n",
    "        params_dict = {}\n",
    "        self._flatten_params(params_dict)\n",
    "        for key, param in params_dict.items():\n",
    "            param.data = npz[key]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & Save test with `MNIST`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "import dezero\n",
    "from dezero import optimizers\n",
    "from dezero import DataLoader\n",
    "\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP\n",
    "from dezero.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "hidden_size = 1000\n",
    "\n",
    "train_set = MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "\n",
    "model = MLP((hidden_size, 10))\n",
    "optimizer = optimizers.SGD(lr=0.1).setup(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with `gpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "train loss: 0.3995, accuracy: 0.8851, time: 4.5996[sec]\n",
      "epoch : 2\n",
      "train loss: 0.3504, accuracy: 0.8976, time: 4.4648[sec]\n",
      "epoch : 3\n",
      "train loss: 0.3289, accuracy: 0.9047, time: 4.5244[sec]\n",
      "epoch : 4\n",
      "train loss: 0.3160, accuracy: 0.9085, time: 4.5520[sec]\n",
      "epoch : 5\n",
      "train loss: 0.3058, accuracy: 0.9111, time: 4.5762[sec]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if dezero.cuda.gpu_enable:\n",
    "    train_loader.to_gpu()\n",
    "    model.to_gpu()\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    start = time.time()\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = F.softmax_cross_entropy(y_pred, y)\n",
    "        acc = F.accuracy(y_pred, y)\n",
    "        \n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        \n",
    "        sum_loss += float(loss.data) * len(y)\n",
    "        sum_acc += float(acc.data) * len(y)\n",
    "    \n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "    elasped_time = time.time() - start\n",
    "    \n",
    "    print('epoch : {}'.format(epoch + 1))\n",
    "    print('train loss: {:.4f}, accuracy: {:.4f}, time: {:.4f}[sec]'.format(avg_loss, avg_acc, elasped_time))\n",
    "\n",
    "model.save_weights('my_mlp.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset and test :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "hidden_size = 1000\n",
    "\n",
    "train_set = MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "\n",
    "model = MLP((hidden_size, 10))\n",
    "optimizer = optimizers.SGD(lr=0.1).setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "train loss: 0.2977, accuracy: 0.9142, time: 4.5690[sec]\n",
      "epoch : 2\n",
      "train loss: 0.2922, accuracy: 0.9158, time: 4.4997[sec]\n",
      "epoch : 3\n",
      "train loss: 0.2861, accuracy: 0.9175, time: 4.6459[sec]\n",
      "epoch : 4\n",
      "train loss: 0.2818, accuracy: 0.9192, time: 4.9926[sec]\n",
      "epoch : 5\n",
      "train loss: 0.2768, accuracy: 0.9208, time: 5.0784[sec]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('my_mlp.npz'):\n",
    "    model.load_weights('my_mlp.npz')\n",
    "\n",
    "if dezero.cuda.gpu_enable:\n",
    "    train_loader.to_gpu()\n",
    "    model.to_gpu()\n",
    "    \n",
    "for epoch in range(max_epoch):\n",
    "    start = time.time()\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = F.softmax_cross_entropy(y_pred, y)\n",
    "        acc = F.accuracy(y_pred, y)\n",
    "        \n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        \n",
    "        sum_loss += float(loss.data) * len(y)\n",
    "        sum_acc += float(acc.data) * len(y)\n",
    "    \n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "    elasped_time = time.time() - start\n",
    "    \n",
    "    print('epoch : {}'.format(epoch + 1))\n",
    "    print('train loss: {:.4f}, accuracy: {:.4f}, time: {:.4f}[sec]'.format(avg_loss, avg_acc, elasped_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working GOOD!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### with `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "hidden_size = 1000\n",
    "\n",
    "train_set = MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "\n",
    "model = MLP((hidden_size, 10))\n",
    "optimizer = optimizers.SGD(lr=0.1).setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "train loss: 0.9763, accuracy: 0.7235, time: 5.8883[sec]\n",
      "epoch : 2\n",
      "train loss: 0.4001, accuracy: 0.8842, time: 5.6606[sec]\n",
      "epoch : 3\n",
      "train loss: 0.3522, accuracy: 0.8978, time: 5.9509[sec]\n",
      "epoch : 4\n",
      "train loss: 0.3294, accuracy: 0.9044, time: 5.5500[sec]\n",
      "epoch : 5\n",
      "train loss: 0.3151, accuracy: 0.9078, time: 6.0811[sec]\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(max_epoch):\n",
    "    start = time.time()\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = F.softmax_cross_entropy(y_pred, y)\n",
    "        acc = F.accuracy(y_pred, y)\n",
    "        \n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        \n",
    "        sum_loss += float(loss.data) * len(y)\n",
    "        sum_acc += float(acc.data) * len(y)\n",
    "    \n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "    elasped_time = time.time() - start\n",
    "    \n",
    "    print('epoch : {}'.format(epoch + 1))\n",
    "    print('train loss: {:.4f}, accuracy: {:.4f}, time: {:.4f}[sec]'.format(avg_loss, avg_acc, elasped_time))\n",
    "\n",
    "model.save_weights('my_mlp.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset and test :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 5\n",
    "batch_size = 100\n",
    "hidden_size = 1000\n",
    "\n",
    "train_set = MNIST(train=True)\n",
    "train_loader = DataLoader(train_set, batch_size)\n",
    "\n",
    "model = MLP((hidden_size, 10))\n",
    "optimizer = optimizers.SGD(lr=0.1).setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch : 1\n",
      "train loss: 0.3067, accuracy: 0.9108, time: 5.6444[sec]\n",
      "epoch : 2\n",
      "train loss: 0.2988, accuracy: 0.9131, time: 5.5396[sec]\n",
      "epoch : 3\n",
      "train loss: 0.2925, accuracy: 0.9165, time: 5.7961[sec]\n",
      "epoch : 4\n",
      "train loss: 0.2868, accuracy: 0.9175, time: 6.0873[sec]\n",
      "epoch : 5\n",
      "train loss: 0.2810, accuracy: 0.9197, time: 6.2140[sec]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('my_mlp.npz'):\n",
    "    model.load_weights('my_mlp.npz')\n",
    "    \n",
    "for epoch in range(max_epoch):\n",
    "    start = time.time()\n",
    "    sum_loss, sum_acc = 0, 0\n",
    "    \n",
    "    for x, y in train_loader:\n",
    "        \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        loss = F.softmax_cross_entropy(y_pred, y)\n",
    "        acc = F.accuracy(y_pred, y)\n",
    "        \n",
    "        model.cleargrads()\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "        \n",
    "        sum_loss += float(loss.data) * len(y)\n",
    "        sum_acc += float(acc.data) * len(y)\n",
    "    \n",
    "    avg_loss = sum_loss / len(train_set)\n",
    "    avg_acc = sum_acc / len(train_set)\n",
    "    elasped_time = time.time() - start\n",
    "    \n",
    "    print('epoch : {}'.format(epoch + 1))\n",
    "    print('train loss: {:.4f}, accuracy: {:.4f}, time: {:.4f}[sec]'.format(avg_loss, avg_acc, elasped_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Also working GOOD!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
